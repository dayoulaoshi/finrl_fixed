{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "-G6H6HsRTFLn",
   "metadata": {
    "id": "-G6H6HsRTFLn"
   },
   "source": [
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/AI4Finance-Foundation/FinRL-Tutorials/blob/master/1-Introduction/China_A_share_market_tushare.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ShYRMdBTFLp",
   "metadata": {
    "id": "3ShYRMdBTFLp"
   },
   "source": [
    "## Quantitative trading in China A stock market with FinRL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pBU3DdPFTFLp",
   "metadata": {
    "id": "pBU3DdPFTFLp"
   },
   "source": [
    "Install FinRL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51W37k2_TFLq",
   "metadata": {
    "id": "51W37k2_TFLq"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wrds in /home/youyou/anaconda3/envs/FinEnv/lib/python3.10/site-packages (3.1.6)\n",
      "Requirement already satisfied: numpy in /home/youyou/anaconda3/envs/FinEnv/lib/python3.10/site-packages (from wrds) (1.25.2)\n",
      "Requirement already satisfied: pandas in /home/youyou/anaconda3/envs/FinEnv/lib/python3.10/site-packages (from wrds) (1.4.3)\n",
      "Requirement already satisfied: psycopg2-binary in /home/youyou/anaconda3/envs/FinEnv/lib/python3.10/site-packages (from wrds) (2.9.7)\n",
      "Requirement already satisfied: scipy in /home/youyou/anaconda3/envs/FinEnv/lib/python3.10/site-packages (from wrds) (1.11.1)\n",
      "Requirement already satisfied: sqlalchemy<2 in /home/youyou/anaconda3/envs/FinEnv/lib/python3.10/site-packages (from wrds) (1.4.49)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /home/youyou/anaconda3/envs/FinEnv/lib/python3.10/site-packages (from sqlalchemy<2->wrds) (2.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/youyou/anaconda3/envs/FinEnv/lib/python3.10/site-packages (from pandas->wrds) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/youyou/anaconda3/envs/FinEnv/lib/python3.10/site-packages (from pandas->wrds) (2022.7)\n",
      "Requirement already satisfied: six>=1.5 in /home/youyou/anaconda3/envs/FinEnv/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas->wrds) (1.16.0)\n",
      "Requirement already satisfied: swig in /home/youyou/anaconda3/envs/FinEnv/lib/python3.10/site-packages (4.1.1)\n",
      "^C\n",
      "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'condacolab'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m get_ipython()\u001b[39m.\u001b[39msystem(\u001b[39m'\u001b[39m\u001b[39mpip install swig\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m get_ipython()\u001b[39m.\u001b[39msystem(\u001b[39m'\u001b[39m\u001b[39mpip install -q condacolab\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mcondacolab\u001b[39;00m\n\u001b[1;32m      5\u001b[0m condacolab\u001b[39m.\u001b[39minstall()\n\u001b[1;32m      6\u001b[0m get_ipython()\u001b[39m.\u001b[39msystem(\u001b[39m'\u001b[39m\u001b[39mapt-get update -y -qq && apt-get install -y -qq cmake libopenmpi-dev python3-dev zlib1g-dev libgl1-mesa-glx swig\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'condacolab'"
     ]
    }
   ],
   "source": [
    "!pip install wrds\n",
    "!pip install swig\n",
    "!pip install -q condacolab\n",
    "import condacolab\n",
    "condacolab.install()\n",
    "!apt-get update -y -qq && apt-get install -y -qq cmake libopenmpi-dev python3-dev zlib1g-dev libgl1-mesa-glx swig\n",
    "!pip install git+https://github.com/AI4Finance-Foundation/FinRL.git\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ZmuaPTCTFLr",
   "metadata": {
    "id": "9ZmuaPTCTFLr"
   },
   "source": [
    "Install other libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "q6T3o9yTTFLr",
   "metadata": {
    "id": "q6T3o9yTTFLr"
   },
   "outputs": [],
   "source": [
    "!pip install stockstats\n",
    "!pip install tushare\n",
    "#install talib\n",
    "!wget http://prdownloads.sourceforge.net/ta-lib/ta-lib-0.4.0-src.tar.gz \n",
    "!tar xvzf ta-lib-0.4.0-src.tar.gz\n",
    "import os\n",
    "os.chdir('ta-lib') \n",
    "!./configure --prefix=/usr\n",
    "!make\n",
    "!make install\n",
    "#!sudo make install # Sometimes it need root \n",
    "os.chdir('../')\n",
    "!pip install TA-Lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "DrReji1OTFLr",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DrReji1OTFLr",
    "outputId": "325c38e3-ca71-4b58-e0be-104e15011fe2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/\n",
      "fatal: destination path 'FinRL-Meta' already exists and is not an empty directory.\n",
      "/FinRL-Meta\n"
     ]
    }
   ],
   "source": [
    "%cd /\n",
    "!git clone https://github.com/AI4Finance-Foundation/FinRL-Meta\n",
    "%cd /FinRL-Meta/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af82514f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/hchen/Desktop/FinRL-Tutorials/1-Introduction'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb00e4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"meta\"]='/home/youyou/workspace/FinRL-Tutorials'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "C-MYxgpJTMGP",
   "metadata": {
    "id": "C-MYxgpJTMGP"
   },
   "source": [
    "## Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "Vx_hcZwgTKQp",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Vx_hcZwgTKQp",
    "outputId": "d6b36801-3064-4251-aadd-2396cb03ad5d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALL Modules have been imported!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('/Users/hchen/Desktop/FinRL-Tutorials')\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pandas as pd \n",
    "from IPython import display\n",
    "\n",
    "display.set_matplotlib_formats(\"svg\")\n",
    "\n",
    "from meta import config \n",
    "from meta.data_processor import DataProcessor \n",
    "from main import check_and_make_directories \n",
    "from meta.data_processors.tushare import Tushare, ReturnPlotter \n",
    "from meta.env_stock_trading.env_stocktrading_China_A_shares import StockTradingEnv \n",
    "from agents.stablebaselines3_models import DRLAgent \n",
    "import os \n",
    "from typing import List \n",
    "from argparse import ArgumentParser \n",
    "from meta import config \n",
    "from meta.config_tickers import DOW_30_TICKER \n",
    "from meta.config import ( DATA_SAVE_DIR, TRAINED_MODEL_DIR, TENSORBOARD_LOG_DIR, RESULTS_DIR, INDICATORS, TRAIN_START_DATE, TRAIN_END_DATE, TEST_START_DATE, TEST_END_DATE, TRADE_START_DATE, TRADE_END_DATE, ERL_PARAMS, RLlib_PARAMS, SAC_PARAMS, ALPACA_API_KEY, ALPACA_API_SECRET, ALPACA_API_BASE_URL, )\n",
    "\n",
    "import pyfolio\n",
    "from pyfolio import timeseries\n",
    "\n",
    "pd.options.display.max_columns = None\n",
    "\n",
    "print(\"ALL Modules have been imported!\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "FRQz2ptSTjPJ",
   "metadata": {
    "id": "FRQz2ptSTjPJ"
   },
   "source": [
    "## Create Folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "pmttRZWWTXcd",
   "metadata": {
    "id": "pmttRZWWTXcd"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "''' \n",
    "use check_and_make_directories() to replace the following\n",
    "conda\n",
    "if not os.path.exists(\"./datasets\"): \n",
    "  os.makedirs(\"./datasets\") \n",
    "if not os.path.exists(\"./trained_models\"): \n",
    "  os.makedirs(\"./trained_models\") \n",
    "if not os.path.exists(\"./tensorboard_log\"): \n",
    "  os.makedirs(\"./tensorboard_log\") \n",
    "if not os.path.exists(\"./results\"): \n",
    "  os.makedirs(\"./results\") \n",
    "'''\n",
    "\n",
    "\n",
    "check_and_make_directories([DATA_SAVE_DIR, TRAINED_MODEL_DIR, TENSORBOARD_LOG_DIR, RESULTS_DIR])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "94s2JtmxTuLq",
   "metadata": {
    "id": "94s2JtmxTuLq"
   },
   "source": [
    "## Download data, cleaning and feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "xpPTz-xDTovy",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xpPTz-xDTovy",
    "outputId": "40df5f90-6211-452c-ee63-2dc2c849b370"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tushare successfully connected\n"
     ]
    }
   ],
   "source": [
    "ticker_list = ['600000.SH', '600009.SH', '600016.SH', '600028.SH', '600030.SH', '600031.SH', '600036.SH', '600050.SH', '600104.SH', '600196.SH', '600276.SH', '600309.SH', '600519.SH', '600547.SH', '600570.SH']\n",
    "\n",
    "#ticker_list = [ '600547.SH', '600570.SH']\n",
    "\n",
    "TRAIN_START_DATE = '2015-01-01' \n",
    "TRAIN_END_DATE= '2019-08-01' \n",
    "TRADE_START_DATE = '2019-08-01' \n",
    "TRADE_END_DATE = '2020-01-03'\n",
    "\n",
    "TIME_INTERVAL = \"1d\" \n",
    "kwargs = {} \n",
    "kwargs['token'] = '27080ec403c0218f96f388bca1b1d85329d563c91a43672239619ef5' \n",
    "p = DataProcessor(data_source='tushare', start_date=TRAIN_START_DATE, end_date=TRADE_END_DATE, time_interval=TIME_INTERVAL, **kwargs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "svZh2OT0T7PG",
   "metadata": {
    "id": "svZh2OT0T7PG"
   },
   "source": [
    "### Download and Clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "v_PzruLIT3D1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v_PzruLIT3D1",
    "outputId": "fa4b9030-f8ff-41a3-abef-77be4f9d37ce"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 6/15 [00:45<01:37, 10.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTPConnectionPool(host='127.0.0.1', port=15236): Read timed out. (read timeout=30)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 9/15 [01:34<01:18, 13.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTPConnectionPool(host='127.0.0.1', port=15236): Read timed out. (read timeout=30)\n",
      "HTTPConnectionPool(host='127.0.0.1', port=15236): Read timed out. (read timeout=30)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [03:20<00:00, 13.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download complete! Dataset saved to ./data/dataset.csv. \n",
      "Shape of DataFrame: (17960, 8)\n",
      "Shape of DataFrame:  (18315, 8)\n"
     ]
    }
   ],
   "source": [
    "p.download_data(ticker_list=ticker_list)\n",
    "p.clean_data()\n",
    "p.fillna()\n",
    "\n",
    "# p.load_data(\"./data/dataset.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b381745",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tic</th>\n",
       "      <th>time</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>adjusted_close</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>600000.SH</td>\n",
       "      <td>2015-01-05</td>\n",
       "      <td>15.88</td>\n",
       "      <td>16.25</td>\n",
       "      <td>15.56</td>\n",
       "      <td>16.07</td>\n",
       "      <td>16.07</td>\n",
       "      <td>5135687.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>600009.SH</td>\n",
       "      <td>2015-01-05</td>\n",
       "      <td>19.82</td>\n",
       "      <td>20.91</td>\n",
       "      <td>19.82</td>\n",
       "      <td>20.53</td>\n",
       "      <td>20.53</td>\n",
       "      <td>371485.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>600016.SH</td>\n",
       "      <td>2015-01-05</td>\n",
       "      <td>10.87</td>\n",
       "      <td>10.96</td>\n",
       "      <td>10.50</td>\n",
       "      <td>10.78</td>\n",
       "      <td>10.78</td>\n",
       "      <td>9138873.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>600028.SH</td>\n",
       "      <td>2015-01-05</td>\n",
       "      <td>6.59</td>\n",
       "      <td>7.14</td>\n",
       "      <td>6.45</td>\n",
       "      <td>7.14</td>\n",
       "      <td>7.14</td>\n",
       "      <td>11864996.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>600030.SH</td>\n",
       "      <td>2015-01-05</td>\n",
       "      <td>33.90</td>\n",
       "      <td>35.25</td>\n",
       "      <td>33.01</td>\n",
       "      <td>34.66</td>\n",
       "      <td>34.66</td>\n",
       "      <td>6986272.15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         tic        time   open   high    low  close  adjusted_close  \\\n",
       "0  600000.SH  2015-01-05  15.88  16.25  15.56  16.07           16.07   \n",
       "1  600009.SH  2015-01-05  19.82  20.91  19.82  20.53           20.53   \n",
       "2  600016.SH  2015-01-05  10.87  10.96  10.50  10.78           10.78   \n",
       "3  600028.SH  2015-01-05   6.59   7.14   6.45   7.14            7.14   \n",
       "4  600030.SH  2015-01-05  33.90  35.25  33.01  34.66           34.66   \n",
       "\n",
       "        volume  \n",
       "0   5135687.09  \n",
       "1    371485.54  \n",
       "2   9138873.70  \n",
       "3  11864996.45  \n",
       "4   6986272.15  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.dataframe.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "tsHu-XT_T_vQ",
   "metadata": {
    "id": "tsHu-XT_T_vQ"
   },
   "source": [
    "### Add technical indicator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "VfniyyQQT3nq",
   "metadata": {
    "id": "VfniyyQQT3nq"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tech_indicator_list:  ['macd', 'boll_ub', 'boll_lb', 'rsi_30', 'cci_30', 'dx_30', 'close_30_sma', 'close_60_sma']\n",
      "indicator:  macd\n",
      "indicator:  boll_ub\n",
      "indicator:  boll_lb\n",
      "indicator:  rsi_30\n",
      "indicator:  cci_30\n",
      "indicator:  dx_30\n",
      "indicator:  close_30_sma\n",
      "indicator:  close_60_sma\n",
      "Succesfully add technical indicators\n",
      "Shape of DataFrame:  (18270, 17)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tic</th>\n",
       "      <th>time</th>\n",
       "      <th>index</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>adjusted_close</th>\n",
       "      <th>volume</th>\n",
       "      <th>macd</th>\n",
       "      <th>boll_ub</th>\n",
       "      <th>boll_lb</th>\n",
       "      <th>rsi_30</th>\n",
       "      <th>cci_30</th>\n",
       "      <th>dx_30</th>\n",
       "      <th>close_30_sma</th>\n",
       "      <th>close_60_sma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>600000.SH</td>\n",
       "      <td>2015-01-08</td>\n",
       "      <td>45</td>\n",
       "      <td>15.87</td>\n",
       "      <td>15.88</td>\n",
       "      <td>15.20</td>\n",
       "      <td>15.25</td>\n",
       "      <td>15.25</td>\n",
       "      <td>3306271.72</td>\n",
       "      <td>-0.032571</td>\n",
       "      <td>16.617911</td>\n",
       "      <td>15.012089</td>\n",
       "      <td>6.058641</td>\n",
       "      <td>-125.593009</td>\n",
       "      <td>23.014040</td>\n",
       "      <td>15.8150</td>\n",
       "      <td>15.8150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>600009.SH</td>\n",
       "      <td>2015-01-08</td>\n",
       "      <td>46</td>\n",
       "      <td>20.18</td>\n",
       "      <td>20.18</td>\n",
       "      <td>19.73</td>\n",
       "      <td>20.00</td>\n",
       "      <td>20.00</td>\n",
       "      <td>198117.45</td>\n",
       "      <td>-0.016008</td>\n",
       "      <td>20.663897</td>\n",
       "      <td>19.736103</td>\n",
       "      <td>12.828915</td>\n",
       "      <td>-90.842491</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>20.2000</td>\n",
       "      <td>20.2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>600016.SH</td>\n",
       "      <td>2015-01-08</td>\n",
       "      <td>47</td>\n",
       "      <td>10.61</td>\n",
       "      <td>10.66</td>\n",
       "      <td>10.09</td>\n",
       "      <td>10.20</td>\n",
       "      <td>10.20</td>\n",
       "      <td>4851684.17</td>\n",
       "      <td>-0.018247</td>\n",
       "      <td>10.957604</td>\n",
       "      <td>9.997396</td>\n",
       "      <td>11.862558</td>\n",
       "      <td>-99.887006</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>10.4775</td>\n",
       "      <td>10.4775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>600028.SH</td>\n",
       "      <td>2015-01-08</td>\n",
       "      <td>48</td>\n",
       "      <td>7.09</td>\n",
       "      <td>7.41</td>\n",
       "      <td>6.83</td>\n",
       "      <td>6.85</td>\n",
       "      <td>6.85</td>\n",
       "      <td>8190902.35</td>\n",
       "      <td>-0.008227</td>\n",
       "      <td>7.342000</td>\n",
       "      <td>6.743000</td>\n",
       "      <td>27.409248</td>\n",
       "      <td>36.578171</td>\n",
       "      <td>64.934862</td>\n",
       "      <td>7.0425</td>\n",
       "      <td>7.0425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>600030.SH</td>\n",
       "      <td>2015-01-08</td>\n",
       "      <td>49</td>\n",
       "      <td>36.40</td>\n",
       "      <td>36.70</td>\n",
       "      <td>34.68</td>\n",
       "      <td>35.25</td>\n",
       "      <td>35.25</td>\n",
       "      <td>6376268.69</td>\n",
       "      <td>0.032910</td>\n",
       "      <td>36.576444</td>\n",
       "      <td>33.808556</td>\n",
       "      <td>61.517448</td>\n",
       "      <td>47.947020</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>35.1925</td>\n",
       "      <td>35.1925</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         tic        time  index   open   high    low  close  adjusted_close  \\\n",
       "0  600000.SH  2015-01-08     45  15.87  15.88  15.20  15.25           15.25   \n",
       "1  600009.SH  2015-01-08     46  20.18  20.18  19.73  20.00           20.00   \n",
       "2  600016.SH  2015-01-08     47  10.61  10.66  10.09  10.20           10.20   \n",
       "3  600028.SH  2015-01-08     48   7.09   7.41   6.83   6.85            6.85   \n",
       "4  600030.SH  2015-01-08     49  36.40  36.70  34.68  35.25           35.25   \n",
       "\n",
       "       volume      macd    boll_ub    boll_lb     rsi_30      cci_30  \\\n",
       "0  3306271.72 -0.032571  16.617911  15.012089   6.058641 -125.593009   \n",
       "1   198117.45 -0.016008  20.663897  19.736103  12.828915  -90.842491   \n",
       "2  4851684.17 -0.018247  10.957604   9.997396  11.862558  -99.887006   \n",
       "3  8190902.35 -0.008227   7.342000   6.743000  27.409248   36.578171   \n",
       "4  6376268.69  0.032910  36.576444  33.808556  61.517448   47.947020   \n",
       "\n",
       "        dx_30  close_30_sma  close_60_sma  \n",
       "0   23.014040       15.8150       15.8150  \n",
       "1  100.000000       20.2000       20.2000  \n",
       "2  100.000000       10.4775       10.4775  \n",
       "3   64.934862        7.0425        7.0425  \n",
       "4  100.000000       35.1925       35.1925  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.add_technical_indicator(config.INDICATORS) \n",
    "p.fillna()\n",
    "\n",
    "p.dataframe.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cKZk3jGuUR34",
   "metadata": {
    "id": "cKZk3jGuUR34"
   },
   "source": [
    "## Split training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "SuKbrwflUVeU",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SuKbrwflUVeU",
    "outputId": "7596367b-670d-4d6c-b439-033075d87589"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(train.tic.unique()): 15\n"
     ]
    }
   ],
   "source": [
    "train = p.data_split(p.dataframe, TRAIN_START_DATE, TRAIN_END_DATE) \n",
    "\n",
    "print(f\"len(train.tic.unique()): {len(train.tic.unique())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ONAnSMBUWyu",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5ONAnSMBUWyu",
    "outputId": "5bdf45d0-7689-4d31-dfa6-cbcbe8e64827"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train.tic.unique(): ['600000.SH' '600009.SH' '600016.SH' '600028.SH' '600030.SH' '600031.SH'\n",
      " '600036.SH' '600050.SH' '600104.SH' '600196.SH' '600276.SH' '600309.SH'\n",
      " '600519.SH' '600547.SH' '600570.SH']\n"
     ]
    }
   ],
   "source": [
    "print(f\"train.tic.unique(): {train.tic.unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "BXF8hYDvUXfv",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BXF8hYDvUXfv",
    "outputId": "a08ebe19-0107-4e31-c6df-816c846aa3f2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tic</th>\n",
       "      <th>time</th>\n",
       "      <th>index</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>adjusted_close</th>\n",
       "      <th>volume</th>\n",
       "      <th>macd</th>\n",
       "      <th>boll_ub</th>\n",
       "      <th>boll_lb</th>\n",
       "      <th>rsi_30</th>\n",
       "      <th>cci_30</th>\n",
       "      <th>dx_30</th>\n",
       "      <th>close_30_sma</th>\n",
       "      <th>close_60_sma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>600000.SH</td>\n",
       "      <td>2015-01-08</td>\n",
       "      <td>45</td>\n",
       "      <td>15.87</td>\n",
       "      <td>15.88</td>\n",
       "      <td>15.20</td>\n",
       "      <td>15.25</td>\n",
       "      <td>15.25</td>\n",
       "      <td>3306271.72</td>\n",
       "      <td>-0.032571</td>\n",
       "      <td>16.617911</td>\n",
       "      <td>15.012089</td>\n",
       "      <td>6.058641</td>\n",
       "      <td>-125.593009</td>\n",
       "      <td>23.014040</td>\n",
       "      <td>15.8150</td>\n",
       "      <td>15.8150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>600009.SH</td>\n",
       "      <td>2015-01-08</td>\n",
       "      <td>46</td>\n",
       "      <td>20.18</td>\n",
       "      <td>20.18</td>\n",
       "      <td>19.73</td>\n",
       "      <td>20.00</td>\n",
       "      <td>20.00</td>\n",
       "      <td>198117.45</td>\n",
       "      <td>-0.016008</td>\n",
       "      <td>20.663897</td>\n",
       "      <td>19.736103</td>\n",
       "      <td>12.828915</td>\n",
       "      <td>-90.842491</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>20.2000</td>\n",
       "      <td>20.2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>600016.SH</td>\n",
       "      <td>2015-01-08</td>\n",
       "      <td>47</td>\n",
       "      <td>10.61</td>\n",
       "      <td>10.66</td>\n",
       "      <td>10.09</td>\n",
       "      <td>10.20</td>\n",
       "      <td>10.20</td>\n",
       "      <td>4851684.17</td>\n",
       "      <td>-0.018247</td>\n",
       "      <td>10.957604</td>\n",
       "      <td>9.997396</td>\n",
       "      <td>11.862558</td>\n",
       "      <td>-99.887006</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>10.4775</td>\n",
       "      <td>10.4775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>600028.SH</td>\n",
       "      <td>2015-01-08</td>\n",
       "      <td>48</td>\n",
       "      <td>7.09</td>\n",
       "      <td>7.41</td>\n",
       "      <td>6.83</td>\n",
       "      <td>6.85</td>\n",
       "      <td>6.85</td>\n",
       "      <td>8190902.35</td>\n",
       "      <td>-0.008227</td>\n",
       "      <td>7.342000</td>\n",
       "      <td>6.743000</td>\n",
       "      <td>27.409248</td>\n",
       "      <td>36.578171</td>\n",
       "      <td>64.934862</td>\n",
       "      <td>7.0425</td>\n",
       "      <td>7.0425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>600030.SH</td>\n",
       "      <td>2015-01-08</td>\n",
       "      <td>49</td>\n",
       "      <td>36.40</td>\n",
       "      <td>36.70</td>\n",
       "      <td>34.68</td>\n",
       "      <td>35.25</td>\n",
       "      <td>35.25</td>\n",
       "      <td>6376268.69</td>\n",
       "      <td>0.032910</td>\n",
       "      <td>36.576444</td>\n",
       "      <td>33.808556</td>\n",
       "      <td>61.517448</td>\n",
       "      <td>47.947020</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>35.1925</td>\n",
       "      <td>35.1925</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         tic        time  index   open   high    low  close  adjusted_close  \\\n",
       "0  600000.SH  2015-01-08     45  15.87  15.88  15.20  15.25           15.25   \n",
       "0  600009.SH  2015-01-08     46  20.18  20.18  19.73  20.00           20.00   \n",
       "0  600016.SH  2015-01-08     47  10.61  10.66  10.09  10.20           10.20   \n",
       "0  600028.SH  2015-01-08     48   7.09   7.41   6.83   6.85            6.85   \n",
       "0  600030.SH  2015-01-08     49  36.40  36.70  34.68  35.25           35.25   \n",
       "\n",
       "       volume      macd    boll_ub    boll_lb     rsi_30      cci_30  \\\n",
       "0  3306271.72 -0.032571  16.617911  15.012089   6.058641 -125.593009   \n",
       "0   198117.45 -0.016008  20.663897  19.736103  12.828915  -90.842491   \n",
       "0  4851684.17 -0.018247  10.957604   9.997396  11.862558  -99.887006   \n",
       "0  8190902.35 -0.008227   7.342000   6.743000  27.409248   36.578171   \n",
       "0  6376268.69  0.032910  36.576444  33.808556  61.517448   47.947020   \n",
       "\n",
       "        dx_30  close_30_sma  close_60_sma  \n",
       "0   23.014040       15.8150       15.8150  \n",
       "0  100.000000       20.2000       20.2000  \n",
       "0  100.000000       10.4775       10.4775  \n",
       "0   64.934862        7.0425        7.0425  \n",
       "0  100.000000       35.1925       35.1925  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "CnwNoBG5UXSQ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CnwNoBG5UXSQ",
    "outputId": "3bcf1c7a-e9de-4b92-fc7e-069904d9e6e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train.shape: (16695, 17)\n"
     ]
    }
   ],
   "source": [
    "print(f\"train.shape: {train.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "joNhXi_ZUXId",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "joNhXi_ZUXId",
    "outputId": "460b9763-6b0f-4976-f772-4a9a7cda2255"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stock Dimension: 15, State Space: 151\n"
     ]
    }
   ],
   "source": [
    "stock_dimension = len(train.tic.unique()) \n",
    "state_space = stock_dimension * (len(config.INDICATORS) + 2) + 1 \n",
    "\n",
    "print(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d44b6902",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tic</th>\n",
       "      <th>time</th>\n",
       "      <th>index</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>adjusted_close</th>\n",
       "      <th>volume</th>\n",
       "      <th>macd</th>\n",
       "      <th>boll_ub</th>\n",
       "      <th>boll_lb</th>\n",
       "      <th>rsi_30</th>\n",
       "      <th>cci_30</th>\n",
       "      <th>dx_30</th>\n",
       "      <th>close_30_sma</th>\n",
       "      <th>close_60_sma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>600000.SH</td>\n",
       "      <td>2015-01-08</td>\n",
       "      <td>45</td>\n",
       "      <td>15.87</td>\n",
       "      <td>15.88</td>\n",
       "      <td>15.20</td>\n",
       "      <td>15.25</td>\n",
       "      <td>15.25</td>\n",
       "      <td>3306271.72</td>\n",
       "      <td>-0.032571</td>\n",
       "      <td>16.617911</td>\n",
       "      <td>15.012089</td>\n",
       "      <td>6.058641</td>\n",
       "      <td>-125.593009</td>\n",
       "      <td>23.014040</td>\n",
       "      <td>15.8150</td>\n",
       "      <td>15.8150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>600009.SH</td>\n",
       "      <td>2015-01-08</td>\n",
       "      <td>46</td>\n",
       "      <td>20.18</td>\n",
       "      <td>20.18</td>\n",
       "      <td>19.73</td>\n",
       "      <td>20.00</td>\n",
       "      <td>20.00</td>\n",
       "      <td>198117.45</td>\n",
       "      <td>-0.016008</td>\n",
       "      <td>20.663897</td>\n",
       "      <td>19.736103</td>\n",
       "      <td>12.828915</td>\n",
       "      <td>-90.842491</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>20.2000</td>\n",
       "      <td>20.2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>600016.SH</td>\n",
       "      <td>2015-01-08</td>\n",
       "      <td>47</td>\n",
       "      <td>10.61</td>\n",
       "      <td>10.66</td>\n",
       "      <td>10.09</td>\n",
       "      <td>10.20</td>\n",
       "      <td>10.20</td>\n",
       "      <td>4851684.17</td>\n",
       "      <td>-0.018247</td>\n",
       "      <td>10.957604</td>\n",
       "      <td>9.997396</td>\n",
       "      <td>11.862558</td>\n",
       "      <td>-99.887006</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>10.4775</td>\n",
       "      <td>10.4775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>600028.SH</td>\n",
       "      <td>2015-01-08</td>\n",
       "      <td>48</td>\n",
       "      <td>7.09</td>\n",
       "      <td>7.41</td>\n",
       "      <td>6.83</td>\n",
       "      <td>6.85</td>\n",
       "      <td>6.85</td>\n",
       "      <td>8190902.35</td>\n",
       "      <td>-0.008227</td>\n",
       "      <td>7.342000</td>\n",
       "      <td>6.743000</td>\n",
       "      <td>27.409248</td>\n",
       "      <td>36.578171</td>\n",
       "      <td>64.934862</td>\n",
       "      <td>7.0425</td>\n",
       "      <td>7.0425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>600030.SH</td>\n",
       "      <td>2015-01-08</td>\n",
       "      <td>49</td>\n",
       "      <td>36.40</td>\n",
       "      <td>36.70</td>\n",
       "      <td>34.68</td>\n",
       "      <td>35.25</td>\n",
       "      <td>35.25</td>\n",
       "      <td>6376268.69</td>\n",
       "      <td>0.032910</td>\n",
       "      <td>36.576444</td>\n",
       "      <td>33.808556</td>\n",
       "      <td>61.517448</td>\n",
       "      <td>47.947020</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>35.1925</td>\n",
       "      <td>35.1925</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         tic        time  index   open   high    low  close  adjusted_close  \\\n",
       "0  600000.SH  2015-01-08     45  15.87  15.88  15.20  15.25           15.25   \n",
       "0  600009.SH  2015-01-08     46  20.18  20.18  19.73  20.00           20.00   \n",
       "0  600016.SH  2015-01-08     47  10.61  10.66  10.09  10.20           10.20   \n",
       "0  600028.SH  2015-01-08     48   7.09   7.41   6.83   6.85            6.85   \n",
       "0  600030.SH  2015-01-08     49  36.40  36.70  34.68  35.25           35.25   \n",
       "\n",
       "       volume      macd    boll_ub    boll_lb     rsi_30      cci_30  \\\n",
       "0  3306271.72 -0.032571  16.617911  15.012089   6.058641 -125.593009   \n",
       "0   198117.45 -0.016008  20.663897  19.736103  12.828915  -90.842491   \n",
       "0  4851684.17 -0.018247  10.957604   9.997396  11.862558  -99.887006   \n",
       "0  8190902.35 -0.008227   7.342000   6.743000  27.409248   36.578171   \n",
       "0  6376268.69  0.032910  36.576444  33.808556  61.517448   47.947020   \n",
       "\n",
       "        dx_30  close_30_sma  close_60_sma  \n",
       "0   23.014040       15.8150       15.8150  \n",
       "0  100.000000       20.2000       20.2000  \n",
       "0  100.000000       10.4775       10.4775  \n",
       "0   64.934862        7.0425        7.0425  \n",
       "0  100.000000       35.1925       35.1925  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "le09273cUmzH",
   "metadata": {
    "id": "le09273cUmzH"
   },
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "Npwpqkr7UpFF",
   "metadata": {
    "id": "Npwpqkr7UpFF"
   },
   "outputs": [],
   "source": [
    "env_kwargs = { \"stock_dim\": stock_dimension, \"hmax\": 1000, \"initial_amount\": 1000000, \"buy_cost_pct\": 6.87e-5, \"sell_cost_pct\": 1.0687e-3, \"reward_scaling\": 1e-4, \"state_space\": state_space, \"action_space\": stock_dimension, \"tech_indicator_list\": config.INDICATORS, \"print_verbosity\": 1, \"initial_buy\": True, \"hundred_each_trade\": True }\n",
    "# train\n",
    "e_train_gym = StockTradingEnv(df=train, **env_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f1POZL3nUyDY",
   "metadata": {
    "id": "f1POZL3nUyDY"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv'>\n",
      "print(type(env_train)): None\n"
     ]
    }
   ],
   "source": [
    "env_train, _ = e_train_gym.get_sb_env() \n",
    "\n",
    "print(f\"print(type(env_train)): {print(type(env_train))}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "QkY8sVWhU6PH",
   "metadata": {
    "id": "QkY8sVWhU6PH"
   },
   "source": [
    "### DDPG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dLjEviBhUzuc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dLjEviBhUzuc",
    "outputId": "58226aaa-41dc-45ce-9f5c-1e5cb94d27a4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 256, 'buffer_size': 50000, 'learning_rate': 0.0005, 'action_noise': NormalActionNoise(mu=[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], sigma=[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1])}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ddpg/ddpg_13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 2\n",
      "day: 1112, episode: 2\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 976438.59\n",
      "total_reward: -23561.41\n",
      "total_cost: 12149.56\n",
      "total_trades: 16679\n",
      "Sharpe: 0.147\n",
      "=================================\n",
      "Episode: 3\n",
      "day: 1112, episode: 3\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 996647.70\n",
      "total_reward: -3352.30\n",
      "total_cost: 121.30\n",
      "total_trades: 16680\n",
      "Sharpe: 0.374\n",
      "=================================\n",
      "Episode: 4\n",
      "day: 1112, episode: 4\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1007973.81\n",
      "total_reward: 7973.81\n",
      "total_cost: 102.19\n",
      "total_trades: 16680\n",
      "Sharpe: 0.299\n",
      "=================================\n",
      "Episode: 5\n",
      "day: 1112, episode: 5\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 999897.82\n",
      "total_reward: -102.18\n",
      "total_cost: 102.18\n",
      "total_trades: 16680\n",
      "Sharpe: 0.365\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 4         |\n",
      "|    fps             | 81        |\n",
      "|    time_elapsed    | 54        |\n",
      "|    total_timesteps | 4452      |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 49.3      |\n",
      "|    critic_loss     | 139       |\n",
      "|    learning_rate   | 0.0005    |\n",
      "|    n_updates       | 3339      |\n",
      "|    reward          | -1.595553 |\n",
      "----------------------------------\n",
      "Episode: 6\n",
      "day: 1112, episode: 6\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1003886.83\n",
      "total_reward: 3886.83\n",
      "total_cost: 102.17\n",
      "total_trades: 16680\n",
      "Sharpe: 0.296\n",
      "=================================\n",
      "Episode: 7\n",
      "day: 1112, episode: 7\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1305115.40\n",
      "total_reward: 305115.40\n",
      "total_cost: 428.60\n",
      "total_trades: 16680\n",
      "Sharpe: 0.350\n",
      "=================================\n",
      "Episode: 8\n",
      "day: 1112, episode: 8\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1325507.41\n",
      "total_reward: 325507.41\n",
      "total_cost: 428.59\n",
      "total_trades: 16680\n",
      "Sharpe: 0.360\n",
      "=================================\n",
      "Episode: 9\n",
      "day: 1112, episode: 9\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1369855.40\n",
      "total_reward: 369855.40\n",
      "total_cost: 428.60\n",
      "total_trades: 16680\n",
      "Sharpe: 0.382\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 8         |\n",
      "|    fps             | 74        |\n",
      "|    time_elapsed    | 119       |\n",
      "|    total_timesteps | 8904      |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 37.2      |\n",
      "|    critic_loss     | 17        |\n",
      "|    learning_rate   | 0.0005    |\n",
      "|    n_updates       | 7791      |\n",
      "|    reward          | -2.269118 |\n",
      "----------------------------------\n",
      "Episode: 10\n",
      "day: 1112, episode: 10\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1341125.40\n",
      "total_reward: 341125.40\n",
      "total_cost: 428.60\n",
      "total_trades: 16680\n",
      "Sharpe: 0.368\n",
      "=================================\n"
     ]
    }
   ],
   "source": [
    "agent = DRLAgent(env=env_train) \n",
    "DDPG_PARAMS = { \"batch_size\": 256, \"buffer_size\": 50000, \"learning_rate\": 0.0005, \"action_noise\": \"normal\", } \n",
    "POLICY_KWARGS = dict(net_arch=dict(pi=[64, 64], qf=[400, 300])) \n",
    "model_ddpg = agent.get_model(\"ddpg\", model_kwargs=DDPG_PARAMS, policy_kwargs=POLICY_KWARGS)\n",
    "\n",
    "trained_ddpg = agent.train_model(model=model_ddpg, tb_log_name='ddpg', total_timesteps=10000)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ALJ1gqVmVEiU",
   "metadata": {
    "id": "ALJ1gqVmVEiU"
   },
   "source": [
    "### A2C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2F5qCGnNUzm7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2F5qCGnNUzm7",
    "outputId": "b8db239f-7d37-4587-c511-0f2dc4c6f273"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0007}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/a2c/a2c_9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 360      |\n",
      "|    iterations         | 100      |\n",
      "|    time_elapsed       | 1        |\n",
      "|    total_timesteps    | 500      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.84    |\n",
      "|    explained_variance | -0.0681  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 99       |\n",
      "|    policy_loss        | -7.47    |\n",
      "|    reward             | 0.700627 |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 5.39     |\n",
      "------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 370        |\n",
      "|    iterations         | 200        |\n",
      "|    time_elapsed       | 2          |\n",
      "|    total_timesteps    | 1000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -2.86      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 199        |\n",
      "|    policy_loss        | 1.63       |\n",
      "|    reward             | -0.2854911 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 1.75       |\n",
      "--------------------------------------\n",
      "Episode: 12\n",
      "day: 1114, episode: 12\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 873671.26\n",
      "total_reward: -126328.74\n",
      "total_cost: 31876.58\n",
      "total_trades: 2228\n",
      "Sharpe: 0.160\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 369       |\n",
      "|    iterations         | 300       |\n",
      "|    time_elapsed       | 4         |\n",
      "|    total_timesteps    | 1500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.86     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 299       |\n",
      "|    policy_loss        | 0.671     |\n",
      "|    reward             | 0.2254647 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 0.128     |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 373         |\n",
      "|    iterations         | 400         |\n",
      "|    time_elapsed       | 5           |\n",
      "|    total_timesteps    | 2000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -2.87       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 399         |\n",
      "|    policy_loss        | 2.55        |\n",
      "|    reward             | 0.119417526 |\n",
      "|    std                | 1.02        |\n",
      "|    value_loss         | 0.91        |\n",
      "---------------------------------------\n",
      "Episode: 13\n",
      "day: 1114, episode: 13\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 577722.70\n",
      "total_reward: -422277.30\n",
      "total_cost: 24121.30\n",
      "total_trades: 2225\n",
      "Sharpe: -0.504\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 373         |\n",
      "|    iterations         | 500         |\n",
      "|    time_elapsed       | 6           |\n",
      "|    total_timesteps    | 2500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -2.89       |\n",
      "|    explained_variance | 2.38e-07    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 499         |\n",
      "|    policy_loss        | -0.178      |\n",
      "|    reward             | 0.017085975 |\n",
      "|    std                | 1.03        |\n",
      "|    value_loss         | 0.0113      |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 380       |\n",
      "|    iterations         | 600       |\n",
      "|    time_elapsed       | 7         |\n",
      "|    total_timesteps    | 3000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.89     |\n",
      "|    explained_variance | 0.0614    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 599       |\n",
      "|    policy_loss        | 6.82      |\n",
      "|    reward             | 1.8191293 |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 6.06      |\n",
      "-------------------------------------\n",
      "Episode: 14\n",
      "day: 1114, episode: 14\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1142256.23\n",
      "total_reward: 142256.23\n",
      "total_cost: 26607.77\n",
      "total_trades: 2227\n",
      "Sharpe: 0.252\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 383         |\n",
      "|    iterations         | 700         |\n",
      "|    time_elapsed       | 9           |\n",
      "|    total_timesteps    | 3500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -2.9        |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 699         |\n",
      "|    policy_loss        | 0.461       |\n",
      "|    reward             | -0.40133294 |\n",
      "|    std                | 1.03        |\n",
      "|    value_loss         | 0.0311      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 378         |\n",
      "|    iterations         | 800         |\n",
      "|    time_elapsed       | 10          |\n",
      "|    total_timesteps    | 4000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -2.92       |\n",
      "|    explained_variance | 5.96e-08    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 799         |\n",
      "|    policy_loss        | 0.0497      |\n",
      "|    reward             | -0.00088448 |\n",
      "|    std                | 1.04        |\n",
      "|    value_loss         | 0.000756    |\n",
      "---------------------------------------\n",
      "Episode: 15\n",
      "day: 1114, episode: 15\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 870708.24\n",
      "total_reward: -129291.76\n",
      "total_cost: 11108.76\n",
      "total_trades: 2226\n",
      "Sharpe: -0.254\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 379          |\n",
      "|    iterations         | 900          |\n",
      "|    time_elapsed       | 11           |\n",
      "|    total_timesteps    | 4500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -2.95        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 899          |\n",
      "|    policy_loss        | -0.0211      |\n",
      "|    reward             | -0.023759374 |\n",
      "|    std                | 1.06         |\n",
      "|    value_loss         | 0.000303     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 381         |\n",
      "|    iterations         | 1000        |\n",
      "|    time_elapsed       | 13          |\n",
      "|    total_timesteps    | 5000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -2.99       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 999         |\n",
      "|    policy_loss        | 0.00231     |\n",
      "|    reward             | -0.00134928 |\n",
      "|    std                | 1.08        |\n",
      "|    value_loss         | 3.31e-06    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 383           |\n",
      "|    iterations         | 1100          |\n",
      "|    time_elapsed       | 14            |\n",
      "|    total_timesteps    | 5500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -3.05         |\n",
      "|    explained_variance | 1.19e-07      |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1099          |\n",
      "|    policy_loss        | 0.374         |\n",
      "|    reward             | -0.0053747077 |\n",
      "|    std                | 1.11          |\n",
      "|    value_loss         | 0.032         |\n",
      "-----------------------------------------\n",
      "Episode: 16\n",
      "day: 1114, episode: 16\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 831405.37\n",
      "total_reward: -168594.63\n",
      "total_cost: 4384.63\n",
      "total_trades: 2228\n",
      "Sharpe: -0.555\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 385        |\n",
      "|    iterations         | 1200       |\n",
      "|    time_elapsed       | 15         |\n",
      "|    total_timesteps    | 6000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -3.09      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1199       |\n",
      "|    policy_loss        | 0.0223     |\n",
      "|    reward             | -0.0016976 |\n",
      "|    std                | 1.14       |\n",
      "|    value_loss         | 6.42e-05   |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 386       |\n",
      "|    iterations         | 1300      |\n",
      "|    time_elapsed       | 16        |\n",
      "|    total_timesteps    | 6500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -3.13     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1299      |\n",
      "|    policy_loss        | 0.0334    |\n",
      "|    reward             | -0.000476 |\n",
      "|    std                | 1.16      |\n",
      "|    value_loss         | 0.000174  |\n",
      "-------------------------------------\n",
      "Episode: 17\n",
      "day: 1114, episode: 17\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 894890.43\n",
      "total_reward: -105109.57\n",
      "total_cost: 3617.57\n",
      "total_trades: 2228\n",
      "Sharpe: -0.406\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 387         |\n",
      "|    iterations         | 1400        |\n",
      "|    time_elapsed       | 18          |\n",
      "|    total_timesteps    | 7000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -3.18       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1399        |\n",
      "|    policy_loss        | 0.0289      |\n",
      "|    reward             | -0.00131904 |\n",
      "|    std                | 1.19        |\n",
      "|    value_loss         | 6.99e-05    |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 388       |\n",
      "|    iterations         | 1500      |\n",
      "|    time_elapsed       | 19        |\n",
      "|    total_timesteps    | 7500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -3.21     |\n",
      "|    explained_variance | -0.261    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1499      |\n",
      "|    policy_loss        | -16.3     |\n",
      "|    reward             | 1.4126109 |\n",
      "|    std                | 1.2       |\n",
      "|    value_loss         | 32.2      |\n",
      "-------------------------------------\n",
      "Episode: 18\n",
      "day: 1114, episode: 18\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1115514.30\n",
      "total_reward: 115514.30\n",
      "total_cost: 11062.70\n",
      "total_trades: 2228\n",
      "Sharpe: 0.223\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 389         |\n",
      "|    iterations         | 1600        |\n",
      "|    time_elapsed       | 20          |\n",
      "|    total_timesteps    | 8000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -3.23       |\n",
      "|    explained_variance | 0.233       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1599        |\n",
      "|    policy_loss        | 0.196       |\n",
      "|    reward             | -0.21866587 |\n",
      "|    std                | 1.22        |\n",
      "|    value_loss         | 0.475       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 391        |\n",
      "|    iterations         | 1700       |\n",
      "|    time_elapsed       | 21         |\n",
      "|    total_timesteps    | 8500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -3.22      |\n",
      "|    explained_variance | 0.142      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1699       |\n",
      "|    policy_loss        | 6.28       |\n",
      "|    reward             | -0.5255316 |\n",
      "|    std                | 1.21       |\n",
      "|    value_loss         | 4.94       |\n",
      "--------------------------------------\n",
      "Episode: 19\n",
      "day: 1114, episode: 19\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1362090.79\n",
      "total_reward: 362090.79\n",
      "total_cost: 18063.21\n",
      "total_trades: 2227\n",
      "Sharpe: 0.380\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 392        |\n",
      "|    iterations         | 1800       |\n",
      "|    time_elapsed       | 22         |\n",
      "|    total_timesteps    | 9000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -3.23      |\n",
      "|    explained_variance | -0.643     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1799       |\n",
      "|    policy_loss        | 52.4       |\n",
      "|    reward             | 0.47925967 |\n",
      "|    std                | 1.22       |\n",
      "|    value_loss         | 133        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 393        |\n",
      "|    iterations         | 1900       |\n",
      "|    time_elapsed       | 24         |\n",
      "|    total_timesteps    | 9500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -3.23      |\n",
      "|    explained_variance | -2.2       |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1899       |\n",
      "|    policy_loss        | -0.74      |\n",
      "|    reward             | -3.6266108 |\n",
      "|    std                | 1.22       |\n",
      "|    value_loss         | 0.0422     |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 393       |\n",
      "|    iterations         | 2000      |\n",
      "|    time_elapsed       | 25        |\n",
      "|    total_timesteps    | 10000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -3.24     |\n",
      "|    explained_variance | 1.79e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1999      |\n",
      "|    policy_loss        | 20.2      |\n",
      "|    reward             | 0.1632772 |\n",
      "|    std                | 1.23      |\n",
      "|    value_loss         | 33.7      |\n",
      "-------------------------------------\n",
      "Episode: 20\n",
      "day: 1114, episode: 20\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1315429.38\n",
      "total_reward: 315429.38\n",
      "total_cost: 17840.62\n",
      "total_trades: 2227\n",
      "Sharpe: 0.360\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 394       |\n",
      "|    iterations         | 2100      |\n",
      "|    time_elapsed       | 26        |\n",
      "|    total_timesteps    | 10500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -3.26     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2099      |\n",
      "|    policy_loss        | -8.2      |\n",
      "|    reward             | 1.6076059 |\n",
      "|    std                | 1.24      |\n",
      "|    value_loss         | 10.1      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 395        |\n",
      "|    iterations         | 2200       |\n",
      "|    time_elapsed       | 27         |\n",
      "|    total_timesteps    | 11000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -3.27      |\n",
      "|    explained_variance | -3.58e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 2199       |\n",
      "|    policy_loss        | 0.907      |\n",
      "|    reward             | 0.06108656 |\n",
      "|    std                | 1.24       |\n",
      "|    value_loss         | 0.069      |\n",
      "--------------------------------------\n",
      "Episode: 21\n",
      "day: 1114, episode: 21\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1067123.39\n",
      "total_reward: 67123.39\n",
      "total_cost: 17763.61\n",
      "total_trades: 2225\n",
      "Sharpe: 0.209\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 395        |\n",
      "|    iterations         | 2300       |\n",
      "|    time_elapsed       | 29         |\n",
      "|    total_timesteps    | 11500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -3.29      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 2299       |\n",
      "|    policy_loss        | 0.703      |\n",
      "|    reward             | -0.0022112 |\n",
      "|    std                | 1.26       |\n",
      "|    value_loss         | 0.0474     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 395         |\n",
      "|    iterations         | 2400        |\n",
      "|    time_elapsed       | 30          |\n",
      "|    total_timesteps    | 12000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -3.31       |\n",
      "|    explained_variance | -0.036      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 2399        |\n",
      "|    policy_loss        | -3.09       |\n",
      "|    reward             | -0.89884585 |\n",
      "|    std                | 1.27        |\n",
      "|    value_loss         | 3.3         |\n",
      "---------------------------------------\n",
      "Episode: 22\n",
      "day: 1114, episode: 22\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 874434.72\n",
      "total_reward: -125565.28\n",
      "total_cost: 16530.28\n",
      "total_trades: 2228\n",
      "Sharpe: -0.136\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 396           |\n",
      "|    iterations         | 2500          |\n",
      "|    time_elapsed       | 31            |\n",
      "|    total_timesteps    | 12500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -3.34         |\n",
      "|    explained_variance | -1.19e-07     |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 2499          |\n",
      "|    policy_loss        | 0.0761        |\n",
      "|    reward             | -0.0003974921 |\n",
      "|    std                | 1.29          |\n",
      "|    value_loss         | 0.0004        |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 396         |\n",
      "|    iterations         | 2600        |\n",
      "|    time_elapsed       | 32          |\n",
      "|    total_timesteps    | 13000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -3.35       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 2599        |\n",
      "|    policy_loss        | 0.0474      |\n",
      "|    reward             | -0.00088448 |\n",
      "|    std                | 1.3         |\n",
      "|    value_loss         | 0.00032     |\n",
      "---------------------------------------\n",
      "Episode: 23\n",
      "day: 1114, episode: 23\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 736152.64\n",
      "total_reward: -263847.36\n",
      "total_cost: 11590.36\n",
      "total_trades: 2228\n",
      "Sharpe: -0.534\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 397         |\n",
      "|    iterations         | 2700        |\n",
      "|    time_elapsed       | 33          |\n",
      "|    total_timesteps    | 13500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -3.39       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 2699        |\n",
      "|    policy_loss        | -0.222      |\n",
      "|    reward             | -0.19072637 |\n",
      "|    std                | 1.32        |\n",
      "|    value_loss         | 0.00371     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 397         |\n",
      "|    iterations         | 2800        |\n",
      "|    time_elapsed       | 35          |\n",
      "|    total_timesteps    | 14000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -3.42       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 2799        |\n",
      "|    policy_loss        | -0.0733     |\n",
      "|    reward             | -0.00059856 |\n",
      "|    std                | 1.34        |\n",
      "|    value_loss         | 0.000489    |\n",
      "---------------------------------------\n",
      "Episode: 24\n",
      "day: 1114, episode: 24\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 871602.82\n",
      "total_reward: -128397.18\n",
      "total_cost: 7183.18\n",
      "total_trades: 2227\n",
      "Sharpe: -0.499\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 398          |\n",
      "|    iterations         | 2900         |\n",
      "|    time_elapsed       | 36           |\n",
      "|    total_timesteps    | 14500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -3.45        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 2899         |\n",
      "|    policy_loss        | 0.877        |\n",
      "|    reward             | -0.041695014 |\n",
      "|    std                | 1.37         |\n",
      "|    value_loss         | 0.0645       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 398           |\n",
      "|    iterations         | 3000          |\n",
      "|    time_elapsed       | 37            |\n",
      "|    total_timesteps    | 15000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -3.49         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 2999          |\n",
      "|    policy_loss        | 0.0305        |\n",
      "|    reward             | -0.0030601965 |\n",
      "|    std                | 1.39          |\n",
      "|    value_loss         | 0.00017       |\n",
      "-----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 398        |\n",
      "|    iterations         | 3100       |\n",
      "|    time_elapsed       | 38         |\n",
      "|    total_timesteps    | 15500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -3.54      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 3099       |\n",
      "|    policy_loss        | 0.0076     |\n",
      "|    reward             | 0.00155568 |\n",
      "|    std                | 1.43       |\n",
      "|    value_loss         | 1.72e-05   |\n",
      "--------------------------------------\n",
      "Episode: 25\n",
      "day: 1114, episode: 25\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 837019.05\n",
      "total_reward: -162980.95\n",
      "total_cost: 2399.95\n",
      "total_trades: 2228\n",
      "Sharpe: -0.580\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 398         |\n",
      "|    iterations         | 3200        |\n",
      "|    time_elapsed       | 40          |\n",
      "|    total_timesteps    | 16000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -3.6        |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 3199        |\n",
      "|    policy_loss        | -0.0171     |\n",
      "|    reward             | -0.00113776 |\n",
      "|    std                | 1.47        |\n",
      "|    value_loss         | 5.14e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 399         |\n",
      "|    iterations         | 3300        |\n",
      "|    time_elapsed       | 41          |\n",
      "|    total_timesteps    | 16500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -3.68       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 3299        |\n",
      "|    policy_loss        | -0.00655    |\n",
      "|    reward             | -0.00020176 |\n",
      "|    std                | 1.53        |\n",
      "|    value_loss         | 1.29e-05    |\n",
      "---------------------------------------\n",
      "Episode: 26\n",
      "day: 1114, episode: 26\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 878758.07\n",
      "total_reward: -121241.93\n",
      "total_cost: 756.93\n",
      "total_trades: 2228\n",
      "Sharpe: -0.489\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 399        |\n",
      "|    iterations         | 3400       |\n",
      "|    time_elapsed       | 42         |\n",
      "|    total_timesteps    | 17000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -3.73      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 3399       |\n",
      "|    policy_loss        | 0.0493     |\n",
      "|    reward             | 0.00023056 |\n",
      "|    std                | 1.57       |\n",
      "|    value_loss         | 0.000329   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 399        |\n",
      "|    iterations         | 3500       |\n",
      "|    time_elapsed       | 43         |\n",
      "|    total_timesteps    | 17500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -3.79      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 3499       |\n",
      "|    policy_loss        | 0.304      |\n",
      "|    reward             | -0.0008072 |\n",
      "|    std                | 1.62       |\n",
      "|    value_loss         | 0.0065     |\n",
      "--------------------------------------\n",
      "Episode: 27\n",
      "day: 1114, episode: 27\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 868227.04\n",
      "total_reward: -131772.96\n",
      "total_cost: 3094.96\n",
      "total_trades: 2228\n",
      "Sharpe: -0.404\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 399        |\n",
      "|    iterations         | 3600       |\n",
      "|    time_elapsed       | 45         |\n",
      "|    total_timesteps    | 18000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -3.87      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 3599       |\n",
      "|    policy_loss        | -0.0234    |\n",
      "|    reward             | 0.10396297 |\n",
      "|    std                | 1.69       |\n",
      "|    value_loss         | 6.62e-05   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 399        |\n",
      "|    iterations         | 3700       |\n",
      "|    time_elapsed       | 46         |\n",
      "|    total_timesteps    | 18500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -3.91      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 3699       |\n",
      "|    policy_loss        | -0.00493   |\n",
      "|    reward             | -0.0017144 |\n",
      "|    std                | 1.72       |\n",
      "|    value_loss         | 3.85e-06   |\n",
      "--------------------------------------\n",
      "Episode: 28\n",
      "day: 1114, episode: 28\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 837861.63\n",
      "total_reward: -162138.37\n",
      "total_cost: 3593.37\n",
      "total_trades: 2227\n",
      "Sharpe: -0.649\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 400      |\n",
      "|    iterations         | 3800     |\n",
      "|    time_elapsed       | 47       |\n",
      "|    total_timesteps    | 19000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.95    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3799     |\n",
      "|    policy_loss        | -0.055   |\n",
      "|    reward             | -0.00406 |\n",
      "|    std                | 1.76     |\n",
      "|    value_loss         | 0.00029  |\n",
      "------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 400         |\n",
      "|    iterations         | 3900        |\n",
      "|    time_elapsed       | 48          |\n",
      "|    total_timesteps    | 19500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4          |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 3899        |\n",
      "|    policy_loss        | 0.0117      |\n",
      "|    reward             | -0.00060848 |\n",
      "|    std                | 1.8         |\n",
      "|    value_loss         | 8.26e-06    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 400        |\n",
      "|    iterations         | 4000       |\n",
      "|    time_elapsed       | 49         |\n",
      "|    total_timesteps    | 20000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.05      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 3999       |\n",
      "|    policy_loss        | -0.0315    |\n",
      "|    reward             | 0.00124528 |\n",
      "|    std                | 1.85       |\n",
      "|    value_loss         | 0.000112   |\n",
      "--------------------------------------\n",
      "Episode: 29\n",
      "day: 1114, episode: 29\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 878277.84\n",
      "total_reward: -121722.16\n",
      "total_cost: 2695.16\n",
      "total_trades: 2228\n",
      "Sharpe: -0.485\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 401         |\n",
      "|    iterations         | 4100        |\n",
      "|    time_elapsed       | 51          |\n",
      "|    total_timesteps    | 20500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.08       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 4099        |\n",
      "|    policy_loss        | -0.139      |\n",
      "|    reward             | -0.00042496 |\n",
      "|    std                | 1.87        |\n",
      "|    value_loss         | 0.00299     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 401        |\n",
      "|    iterations         | 4200       |\n",
      "|    time_elapsed       | 52         |\n",
      "|    total_timesteps    | 21000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.13      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 4199       |\n",
      "|    policy_loss        | 0.0354     |\n",
      "|    reward             | 0.00063728 |\n",
      "|    std                | 1.92       |\n",
      "|    value_loss         | 0.00011    |\n",
      "--------------------------------------\n",
      "Episode: 30\n",
      "day: 1114, episode: 30\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 876398.52\n",
      "total_reward: -123601.48\n",
      "total_cost: 5210.48\n",
      "total_trades: 2226\n",
      "Sharpe: -0.487\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 401          |\n",
      "|    iterations         | 4300         |\n",
      "|    time_elapsed       | 53           |\n",
      "|    total_timesteps    | 21500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -4.17        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 4299         |\n",
      "|    policy_loss        | -0.0106      |\n",
      "|    reward             | -0.008248635 |\n",
      "|    std                | 1.97         |\n",
      "|    value_loss         | 9.36e-06     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 401         |\n",
      "|    iterations         | 4400        |\n",
      "|    time_elapsed       | 54          |\n",
      "|    total_timesteps    | 22000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.21       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 4399        |\n",
      "|    policy_loss        | -0.148      |\n",
      "|    reward             | -0.00199568 |\n",
      "|    std                | 2.01        |\n",
      "|    value_loss         | 0.00156     |\n",
      "---------------------------------------\n",
      "Episode: 31\n",
      "day: 1114, episode: 31\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 905357.72\n",
      "total_reward: -94642.28\n",
      "total_cost: 5142.28\n",
      "total_trades: 2227\n",
      "Sharpe: -0.364\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 401         |\n",
      "|    iterations         | 4500        |\n",
      "|    time_elapsed       | 56          |\n",
      "|    total_timesteps    | 22500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.25       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 4499        |\n",
      "|    policy_loss        | 0.00896     |\n",
      "|    reward             | -0.00107648 |\n",
      "|    std                | 2.04        |\n",
      "|    value_loss         | 3.46e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 401         |\n",
      "|    iterations         | 4600        |\n",
      "|    time_elapsed       | 57          |\n",
      "|    total_timesteps    | 23000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.3        |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 4599        |\n",
      "|    policy_loss        | -0.00229    |\n",
      "|    reward             | -0.00341088 |\n",
      "|    std                | 2.1         |\n",
      "|    value_loss         | 5.77e-06    |\n",
      "---------------------------------------\n",
      "Episode: 32\n",
      "day: 1114, episode: 32\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 873006.59\n",
      "total_reward: -126993.41\n",
      "total_cost: 5557.41\n",
      "total_trades: 2228\n",
      "Sharpe: -0.493\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 401        |\n",
      "|    iterations         | 4700       |\n",
      "|    time_elapsed       | 58         |\n",
      "|    total_timesteps    | 23500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.34      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 4699       |\n",
      "|    policy_loss        | -3.89      |\n",
      "|    reward             | -1.0345405 |\n",
      "|    std                | 2.14       |\n",
      "|    value_loss         | 1.13       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 402        |\n",
      "|    iterations         | 4800       |\n",
      "|    time_elapsed       | 59         |\n",
      "|    total_timesteps    | 24000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.38      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 4799       |\n",
      "|    policy_loss        | -0.0423    |\n",
      "|    reward             | 0.00114848 |\n",
      "|    std                | 2.18       |\n",
      "|    value_loss         | 0.000247   |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 402          |\n",
      "|    iterations         | 4900         |\n",
      "|    time_elapsed       | 60           |\n",
      "|    total_timesteps    | 24500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -4.38        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 4899         |\n",
      "|    policy_loss        | -0.0201      |\n",
      "|    reward             | 0.0062561575 |\n",
      "|    std                | 2.18         |\n",
      "|    value_loss         | 5.86e-05     |\n",
      "----------------------------------------\n",
      "Episode: 33\n",
      "day: 1114, episode: 33\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 858126.08\n",
      "total_reward: -141873.92\n",
      "total_cost: 15175.92\n",
      "total_trades: 2228\n",
      "Sharpe: -0.457\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 402          |\n",
      "|    iterations         | 5000         |\n",
      "|    time_elapsed       | 62           |\n",
      "|    total_timesteps    | 25000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -4.4         |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 4999         |\n",
      "|    policy_loss        | -0.405       |\n",
      "|    reward             | -0.033666253 |\n",
      "|    std                | 2.21         |\n",
      "|    value_loss         | 0.0103       |\n",
      "----------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 402       |\n",
      "|    iterations         | 5100      |\n",
      "|    time_elapsed       | 63        |\n",
      "|    total_timesteps    | 25500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.43     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 5099      |\n",
      "|    policy_loss        | -0.461    |\n",
      "|    reward             | -0.000748 |\n",
      "|    std                | 2.25      |\n",
      "|    value_loss         | 0.0145    |\n",
      "-------------------------------------\n",
      "Episode: 34\n",
      "day: 1114, episode: 34\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 792776.05\n",
      "total_reward: -207223.95\n",
      "total_cost: 13636.95\n",
      "total_trades: 2228\n",
      "Sharpe: -0.620\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 402         |\n",
      "|    iterations         | 5200        |\n",
      "|    time_elapsed       | 64          |\n",
      "|    total_timesteps    | 26000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.46       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 5199        |\n",
      "|    policy_loss        | -0.266      |\n",
      "|    reward             | -0.08014689 |\n",
      "|    std                | 2.28        |\n",
      "|    value_loss         | 0.00597     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 402           |\n",
      "|    iterations         | 5300          |\n",
      "|    time_elapsed       | 65            |\n",
      "|    total_timesteps    | 26500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -4.48         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 5299          |\n",
      "|    policy_loss        | 0.0381        |\n",
      "|    reward             | -0.0018860642 |\n",
      "|    std                | 2.3           |\n",
      "|    value_loss         | 0.00011       |\n",
      "-----------------------------------------\n",
      "Episode: 35\n",
      "day: 1114, episode: 35\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 824653.11\n",
      "total_reward: -175346.89\n",
      "total_cost: 9452.89\n",
      "total_trades: 2228\n",
      "Sharpe: -0.711\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 402          |\n",
      "|    iterations         | 5400         |\n",
      "|    time_elapsed       | 67           |\n",
      "|    total_timesteps    | 27000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -4.51        |\n",
      "|    explained_variance | 5.96e-08     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 5399         |\n",
      "|    policy_loss        | -0.238       |\n",
      "|    reward             | -0.003843286 |\n",
      "|    std                | 2.33         |\n",
      "|    value_loss         | 0.00352      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 402        |\n",
      "|    iterations         | 5500       |\n",
      "|    time_elapsed       | 68         |\n",
      "|    total_timesteps    | 27500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.54      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 5499       |\n",
      "|    policy_loss        | 0.0313     |\n",
      "|    reward             | -0.0036848 |\n",
      "|    std                | 2.38       |\n",
      "|    value_loss         | 5.14e-05   |\n",
      "--------------------------------------\n",
      "Episode: 36\n",
      "day: 1114, episode: 36\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 880112.91\n",
      "total_reward: -119887.09\n",
      "total_cost: 7523.09\n",
      "total_trades: 2228\n",
      "Sharpe: -0.311\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 402        |\n",
      "|    iterations         | 5600       |\n",
      "|    time_elapsed       | 69         |\n",
      "|    total_timesteps    | 28000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.6       |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 5599       |\n",
      "|    policy_loss        | -1.38      |\n",
      "|    reward             | 0.00131568 |\n",
      "|    std                | 2.45       |\n",
      "|    value_loss         | 0.158      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 402         |\n",
      "|    iterations         | 5700        |\n",
      "|    time_elapsed       | 70          |\n",
      "|    total_timesteps    | 28500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.64       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 5699        |\n",
      "|    policy_loss        | 0.0219      |\n",
      "|    reward             | -0.00310976 |\n",
      "|    std                | 2.5         |\n",
      "|    value_loss         | 3.39e-05    |\n",
      "---------------------------------------\n",
      "Episode: 37\n",
      "day: 1114, episode: 37\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 922002.08\n",
      "total_reward: -77997.92\n",
      "total_cost: 7151.92\n",
      "total_trades: 2227\n",
      "Sharpe: -0.260\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 403        |\n",
      "|    iterations         | 5800       |\n",
      "|    time_elapsed       | 71         |\n",
      "|    total_timesteps    | 29000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.7       |\n",
      "|    explained_variance | 1.79e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 5799       |\n",
      "|    policy_loss        | -9.07      |\n",
      "|    reward             | 0.00585568 |\n",
      "|    std                | 2.58       |\n",
      "|    value_loss         | 28.1       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 403         |\n",
      "|    iterations         | 5900        |\n",
      "|    time_elapsed       | 73          |\n",
      "|    total_timesteps    | 29500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.73       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 5899        |\n",
      "|    policy_loss        | -0.0879     |\n",
      "|    reward             | -0.00251952 |\n",
      "|    std                | 2.62        |\n",
      "|    value_loss         | 0.000755    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 403         |\n",
      "|    iterations         | 6000        |\n",
      "|    time_elapsed       | 74          |\n",
      "|    total_timesteps    | 30000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.78       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 5999        |\n",
      "|    policy_loss        | 0.462       |\n",
      "|    reward             | -0.00171248 |\n",
      "|    std                | 2.68        |\n",
      "|    value_loss         | 0.0097      |\n",
      "---------------------------------------\n",
      "Episode: 38\n",
      "day: 1114, episode: 38\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 847661.20\n",
      "total_reward: -152338.80\n",
      "total_cost: 10570.80\n",
      "total_trades: 2227\n",
      "Sharpe: -0.575\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 403        |\n",
      "|    iterations         | 6100       |\n",
      "|    time_elapsed       | 75         |\n",
      "|    total_timesteps    | 30500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.79      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 6099       |\n",
      "|    policy_loss        | 0.0162     |\n",
      "|    reward             | 0.00064992 |\n",
      "|    std                | 2.7        |\n",
      "|    value_loss         | 1.73e-05   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 403        |\n",
      "|    iterations         | 6200       |\n",
      "|    time_elapsed       | 76         |\n",
      "|    total_timesteps    | 31000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.82      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 6199       |\n",
      "|    policy_loss        | 0.0329     |\n",
      "|    reward             | 0.00272912 |\n",
      "|    std                | 2.74       |\n",
      "|    value_loss         | 5.56e-05   |\n",
      "--------------------------------------\n",
      "Episode: 39\n",
      "day: 1114, episode: 39\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 881246.04\n",
      "total_reward: -118753.96\n",
      "total_cost: 9239.96\n",
      "total_trades: 2228\n",
      "Sharpe: -0.386\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 402        |\n",
      "|    iterations         | 6300       |\n",
      "|    time_elapsed       | 78         |\n",
      "|    total_timesteps    | 31500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.86      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 6299       |\n",
      "|    policy_loss        | 0.0241     |\n",
      "|    reward             | 0.00256048 |\n",
      "|    std                | 2.78       |\n",
      "|    value_loss         | 2.71e-05   |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 403          |\n",
      "|    iterations         | 6400         |\n",
      "|    time_elapsed       | 79           |\n",
      "|    total_timesteps    | 32000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -4.88        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 6399         |\n",
      "|    policy_loss        | 0.0199       |\n",
      "|    reward             | -0.025317296 |\n",
      "|    std                | 2.81         |\n",
      "|    value_loss         | 1.7e-05      |\n",
      "----------------------------------------\n",
      "Episode: 40\n",
      "day: 1114, episode: 40\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 831718.23\n",
      "total_reward: -168281.77\n",
      "total_cost: 14836.77\n",
      "total_trades: 2227\n",
      "Sharpe: -0.494\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 403       |\n",
      "|    iterations         | 6500      |\n",
      "|    time_elapsed       | 80        |\n",
      "|    total_timesteps    | 32500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.9      |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 6499      |\n",
      "|    policy_loss        | 3.44      |\n",
      "|    reward             | 0.0041952 |\n",
      "|    std                | 2.84      |\n",
      "|    value_loss         | 0.453     |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 403         |\n",
      "|    iterations         | 6600        |\n",
      "|    time_elapsed       | 81          |\n",
      "|    total_timesteps    | 33000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.9        |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 6599        |\n",
      "|    policy_loss        | -0.237      |\n",
      "|    reward             | 0.001709447 |\n",
      "|    std                | 2.84        |\n",
      "|    value_loss         | 0.0031      |\n",
      "---------------------------------------\n",
      "Episode: 41\n",
      "day: 1114, episode: 41\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 851824.79\n",
      "total_reward: -148175.21\n",
      "total_cost: 18291.21\n",
      "total_trades: 2228\n",
      "Sharpe: -0.393\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 403           |\n",
      "|    iterations         | 6700          |\n",
      "|    time_elapsed       | 83            |\n",
      "|    total_timesteps    | 33500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -4.91         |\n",
      "|    explained_variance | 5.96e-08      |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 6699          |\n",
      "|    policy_loss        | 2.04          |\n",
      "|    reward             | -0.0028735653 |\n",
      "|    std                | 2.85          |\n",
      "|    value_loss         | 0.36          |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 403         |\n",
      "|    iterations         | 6800        |\n",
      "|    time_elapsed       | 84          |\n",
      "|    total_timesteps    | 34000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.95       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 6799        |\n",
      "|    policy_loss        | -0.392      |\n",
      "|    reward             | -0.00082656 |\n",
      "|    std                | 2.91        |\n",
      "|    value_loss         | 0.00943     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 403         |\n",
      "|    iterations         | 6900        |\n",
      "|    time_elapsed       | 85          |\n",
      "|    total_timesteps    | 34500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.96       |\n",
      "|    explained_variance | -0.000248   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 6899        |\n",
      "|    policy_loss        | 0.0584      |\n",
      "|    reward             | -0.28353727 |\n",
      "|    std                | 2.91        |\n",
      "|    value_loss         | 0.796       |\n",
      "---------------------------------------\n",
      "Episode: 42\n",
      "day: 1114, episode: 42\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 848116.83\n",
      "total_reward: -151883.17\n",
      "total_cost: 20407.17\n",
      "total_trades: 2227\n",
      "Sharpe: -0.479\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 403         |\n",
      "|    iterations         | 7000        |\n",
      "|    time_elapsed       | 86          |\n",
      "|    total_timesteps    | 35000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.95       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 6999        |\n",
      "|    policy_loss        | 0.0243      |\n",
      "|    reward             | -0.00016736 |\n",
      "|    std                | 2.91        |\n",
      "|    value_loss         | 0.000358    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 403           |\n",
      "|    iterations         | 7100          |\n",
      "|    time_elapsed       | 88            |\n",
      "|    total_timesteps    | 35500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -4.97         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 7099          |\n",
      "|    policy_loss        | 0.25          |\n",
      "|    reward             | -0.0041661053 |\n",
      "|    std                | 2.94          |\n",
      "|    value_loss         | 0.018         |\n",
      "-----------------------------------------\n",
      "Episode: 43\n",
      "day: 1114, episode: 43\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 729324.08\n",
      "total_reward: -270675.92\n",
      "total_cost: 24498.92\n",
      "total_trades: 2228\n",
      "Sharpe: -0.651\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 403        |\n",
      "|    iterations         | 7200       |\n",
      "|    time_elapsed       | 89         |\n",
      "|    total_timesteps    | 36000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.99      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 7199       |\n",
      "|    policy_loss        | -8.57      |\n",
      "|    reward             | 0.00297552 |\n",
      "|    std                | 2.97       |\n",
      "|    value_loss         | 3.39       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 403         |\n",
      "|    iterations         | 7300        |\n",
      "|    time_elapsed       | 90          |\n",
      "|    total_timesteps    | 36500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.01       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 7299        |\n",
      "|    policy_loss        | -0.397      |\n",
      "|    reward             | 0.047018617 |\n",
      "|    std                | 3.01        |\n",
      "|    value_loss         | 0.0121      |\n",
      "---------------------------------------\n",
      "Episode: 44\n",
      "day: 1114, episode: 44\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 849330.73\n",
      "total_reward: -150669.27\n",
      "total_cost: 22249.27\n",
      "total_trades: 2227\n",
      "Sharpe: -0.420\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 403         |\n",
      "|    iterations         | 7400        |\n",
      "|    time_elapsed       | 91          |\n",
      "|    total_timesteps    | 37000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.03       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 7399        |\n",
      "|    policy_loss        | -0.0662     |\n",
      "|    reward             | 0.016478194 |\n",
      "|    std                | 3.04        |\n",
      "|    value_loss         | 0.000194    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 403        |\n",
      "|    iterations         | 7500       |\n",
      "|    time_elapsed       | 92         |\n",
      "|    total_timesteps    | 37500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.05      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 7499       |\n",
      "|    policy_loss        | -1.01      |\n",
      "|    reward             | -0.1533364 |\n",
      "|    std                | 3.07       |\n",
      "|    value_loss         | 0.0757     |\n",
      "--------------------------------------\n",
      "Episode: 45\n",
      "day: 1114, episode: 45\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 974658.13\n",
      "total_reward: -25341.87\n",
      "total_cost: 19993.87\n",
      "total_trades: 2228\n",
      "Sharpe: -0.021\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 403      |\n",
      "|    iterations         | 7600     |\n",
      "|    time_elapsed       | 94       |\n",
      "|    total_timesteps    | 38000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.07    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 7599     |\n",
      "|    policy_loss        | 5.22     |\n",
      "|    reward             | -0.00964 |\n",
      "|    std                | 3.11     |\n",
      "|    value_loss         | 2.08     |\n",
      "------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 403         |\n",
      "|    iterations         | 7700        |\n",
      "|    time_elapsed       | 95          |\n",
      "|    total_timesteps    | 38500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.09       |\n",
      "|    explained_variance | -0.00809    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 7699        |\n",
      "|    policy_loss        | 0.756       |\n",
      "|    reward             | -0.29640982 |\n",
      "|    std                | 3.12        |\n",
      "|    value_loss         | 0.789       |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 403       |\n",
      "|    iterations         | 7800      |\n",
      "|    time_elapsed       | 96        |\n",
      "|    total_timesteps    | 39000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.11     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 7799      |\n",
      "|    policy_loss        | 23.3      |\n",
      "|    reward             | 1.1313474 |\n",
      "|    std                | 3.16      |\n",
      "|    value_loss         | 23.5      |\n",
      "-------------------------------------\n",
      "Episode: 46\n",
      "day: 1114, episode: 46\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1035998.20\n",
      "total_reward: 35998.20\n",
      "total_cost: 30970.80\n",
      "total_trades: 2225\n",
      "Sharpe: 0.172\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 403         |\n",
      "|    iterations         | 7900        |\n",
      "|    time_elapsed       | 97          |\n",
      "|    total_timesteps    | 39500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.11       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 7899        |\n",
      "|    policy_loss        | -0.703      |\n",
      "|    reward             | 0.066888645 |\n",
      "|    std                | 3.16        |\n",
      "|    value_loss         | 0.0457      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 403        |\n",
      "|    iterations         | 8000       |\n",
      "|    time_elapsed       | 99         |\n",
      "|    total_timesteps    | 40000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.13      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 7999       |\n",
      "|    policy_loss        | 0.0333     |\n",
      "|    reward             | 0.00052512 |\n",
      "|    std                | 3.19       |\n",
      "|    value_loss         | 0.00136    |\n",
      "--------------------------------------\n",
      "Episode: 47\n",
      "day: 1114, episode: 47\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 863644.86\n",
      "total_reward: -136355.14\n",
      "total_cost: 28267.14\n",
      "total_trades: 2227\n",
      "Sharpe: 0.033\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 403         |\n",
      "|    iterations         | 8100        |\n",
      "|    time_elapsed       | 100         |\n",
      "|    total_timesteps    | 40500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.14       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 8099        |\n",
      "|    policy_loss        | -2.9        |\n",
      "|    reward             | -0.40615195 |\n",
      "|    std                | 3.2         |\n",
      "|    value_loss         | 1.52        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 403         |\n",
      "|    iterations         | 8200        |\n",
      "|    time_elapsed       | 101         |\n",
      "|    total_timesteps    | 41000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.16       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 8199        |\n",
      "|    policy_loss        | -3.97       |\n",
      "|    reward             | -0.16104548 |\n",
      "|    std                | 3.23        |\n",
      "|    value_loss         | 1.01        |\n",
      "---------------------------------------\n",
      "Episode: 48\n",
      "day: 1114, episode: 48\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 750936.44\n",
      "total_reward: -249063.56\n",
      "total_cost: 31118.56\n",
      "total_trades: 2228\n",
      "Sharpe: -0.082\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 403        |\n",
      "|    iterations         | 8300       |\n",
      "|    time_elapsed       | 102        |\n",
      "|    total_timesteps    | 41500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.17      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 8299       |\n",
      "|    policy_loss        | 1.58       |\n",
      "|    reward             | 0.50379705 |\n",
      "|    std                | 3.24       |\n",
      "|    value_loss         | 0.712      |\n",
      "--------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 403           |\n",
      "|    iterations         | 8400          |\n",
      "|    time_elapsed       | 103           |\n",
      "|    total_timesteps    | 42000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -5.17         |\n",
      "|    explained_variance | 1.19e-07      |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 8399          |\n",
      "|    policy_loss        | -1.01         |\n",
      "|    reward             | -0.0027040977 |\n",
      "|    std                | 3.25          |\n",
      "|    value_loss         | 0.284         |\n",
      "-----------------------------------------\n",
      "Episode: 49\n",
      "day: 1114, episode: 49\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 660858.77\n",
      "total_reward: -339141.23\n",
      "total_cost: 29500.23\n",
      "total_trades: 2228\n",
      "Sharpe: -0.185\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 403       |\n",
      "|    iterations         | 8500      |\n",
      "|    time_elapsed       | 105       |\n",
      "|    total_timesteps    | 42500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.18     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 8499      |\n",
      "|    policy_loss        | -2.34     |\n",
      "|    reward             | 0.2937818 |\n",
      "|    std                | 3.27      |\n",
      "|    value_loss         | 1.32      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 403         |\n",
      "|    iterations         | 8600        |\n",
      "|    time_elapsed       | 106         |\n",
      "|    total_timesteps    | 43000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.17       |\n",
      "|    explained_variance | 5.96e-08    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 8599        |\n",
      "|    policy_loss        | 5.03        |\n",
      "|    reward             | -0.32396528 |\n",
      "|    std                | 3.25        |\n",
      "|    value_loss         | 1.38        |\n",
      "---------------------------------------\n",
      "Episode: 50\n",
      "day: 1114, episode: 50\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 735888.12\n",
      "total_reward: -264111.88\n",
      "total_cost: 29907.88\n",
      "total_trades: 2228\n",
      "Sharpe: -0.215\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 403       |\n",
      "|    iterations         | 8700      |\n",
      "|    time_elapsed       | 107       |\n",
      "|    total_timesteps    | 43500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.17     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 8699      |\n",
      "|    policy_loss        | 2.17      |\n",
      "|    reward             | 0.6656827 |\n",
      "|    std                | 3.24      |\n",
      "|    value_loss         | 0.749     |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 403         |\n",
      "|    iterations         | 8800        |\n",
      "|    time_elapsed       | 108         |\n",
      "|    total_timesteps    | 44000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.16       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 8799        |\n",
      "|    policy_loss        | -0.365      |\n",
      "|    reward             | -0.00218432 |\n",
      "|    std                | 3.23        |\n",
      "|    value_loss         | 0.00516     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 403        |\n",
      "|    iterations         | 8900       |\n",
      "|    time_elapsed       | 110        |\n",
      "|    total_timesteps    | 44500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.17      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 8899       |\n",
      "|    policy_loss        | -0.714     |\n",
      "|    reward             | 0.21296176 |\n",
      "|    std                | 3.24       |\n",
      "|    value_loss         | 0.022      |\n",
      "--------------------------------------\n",
      "Episode: 51\n",
      "day: 1114, episode: 51\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 472203.50\n",
      "total_reward: -527796.50\n",
      "total_cost: 25973.50\n",
      "total_trades: 2228\n",
      "Sharpe: -0.897\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 403         |\n",
      "|    iterations         | 9000        |\n",
      "|    time_elapsed       | 111         |\n",
      "|    total_timesteps    | 45000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.2        |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 8999        |\n",
      "|    policy_loss        | 4.53        |\n",
      "|    reward             | -0.07439267 |\n",
      "|    std                | 3.28        |\n",
      "|    value_loss         | 0.927       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 403         |\n",
      "|    iterations         | 9100        |\n",
      "|    time_elapsed       | 112         |\n",
      "|    total_timesteps    | 45500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.2        |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 9099        |\n",
      "|    policy_loss        | 0.0914      |\n",
      "|    reward             | -0.29378018 |\n",
      "|    std                | 3.3         |\n",
      "|    value_loss         | 0.001       |\n",
      "---------------------------------------\n",
      "Episode: 52\n",
      "day: 1114, episode: 52\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1131205.55\n",
      "total_reward: 131205.55\n",
      "total_cost: 27205.45\n",
      "total_trades: 2228\n",
      "Sharpe: 0.296\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 403         |\n",
      "|    iterations         | 9200        |\n",
      "|    time_elapsed       | 113         |\n",
      "|    total_timesteps    | 46000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.23       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 9199        |\n",
      "|    policy_loss        | 0.0159      |\n",
      "|    reward             | -0.18285936 |\n",
      "|    std                | 3.34        |\n",
      "|    value_loss         | 2.38e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 403          |\n",
      "|    iterations         | 9300         |\n",
      "|    time_elapsed       | 115          |\n",
      "|    total_timesteps    | 46500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -5.25        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 9299         |\n",
      "|    policy_loss        | 0.126        |\n",
      "|    reward             | 0.0017964529 |\n",
      "|    std                | 3.38         |\n",
      "|    value_loss         | 0.00199      |\n",
      "----------------------------------------\n",
      "Episode: 53\n",
      "day: 1114, episode: 53\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 778233.31\n",
      "total_reward: -221766.69\n",
      "total_cost: 19004.69\n",
      "total_trades: 2228\n",
      "Sharpe: -0.541\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 403         |\n",
      "|    iterations         | 9400        |\n",
      "|    time_elapsed       | 116         |\n",
      "|    total_timesteps    | 47000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.27       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 9399        |\n",
      "|    policy_loss        | -3.23       |\n",
      "|    reward             | -0.43568012 |\n",
      "|    std                | 3.41        |\n",
      "|    value_loss         | 0.579       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 404         |\n",
      "|    iterations         | 9500        |\n",
      "|    time_elapsed       | 117         |\n",
      "|    total_timesteps    | 47500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.3        |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 9499        |\n",
      "|    policy_loss        | 0.00544     |\n",
      "|    reward             | -0.00074352 |\n",
      "|    std                | 3.47        |\n",
      "|    value_loss         | 7.78e-06    |\n",
      "---------------------------------------\n",
      "Episode: 54\n",
      "day: 1114, episode: 54\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 676343.63\n",
      "total_reward: -323656.37\n",
      "total_cost: 16984.37\n",
      "total_trades: 2228\n",
      "Sharpe: -0.914\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 403        |\n",
      "|    iterations         | 9600       |\n",
      "|    time_elapsed       | 118        |\n",
      "|    total_timesteps    | 48000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.32      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 9599       |\n",
      "|    policy_loss        | 1.69       |\n",
      "|    reward             | 0.00314112 |\n",
      "|    std                | 3.48       |\n",
      "|    value_loss         | 0.11       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 403         |\n",
      "|    iterations         | 9700        |\n",
      "|    time_elapsed       | 120         |\n",
      "|    total_timesteps    | 48500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.35       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 9699        |\n",
      "|    policy_loss        | 0.0284      |\n",
      "|    reward             | -0.03438417 |\n",
      "|    std                | 3.54        |\n",
      "|    value_loss         | 4.15e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 404          |\n",
      "|    iterations         | 9800         |\n",
      "|    time_elapsed       | 121          |\n",
      "|    total_timesteps    | 49000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -5.38        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 9799         |\n",
      "|    policy_loss        | -0.364       |\n",
      "|    reward             | 0.0002942494 |\n",
      "|    std                | 3.59         |\n",
      "|    value_loss         | 0.00736      |\n",
      "----------------------------------------\n",
      "Episode: 55\n",
      "day: 1114, episode: 55\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 911343.24\n",
      "total_reward: -88656.76\n",
      "total_cost: 14688.76\n",
      "total_trades: 2228\n",
      "Sharpe: -0.284\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 404        |\n",
      "|    iterations         | 9900       |\n",
      "|    time_elapsed       | 122        |\n",
      "|    total_timesteps    | 49500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.38      |\n",
      "|    explained_variance | -3.58e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 9899       |\n",
      "|    policy_loss        | 1.6        |\n",
      "|    reward             | 0.78647596 |\n",
      "|    std                | 3.61       |\n",
      "|    value_loss         | 0.0653     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 404        |\n",
      "|    iterations         | 10000      |\n",
      "|    time_elapsed       | 123        |\n",
      "|    total_timesteps    | 50000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.44      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 9999       |\n",
      "|    policy_loss        | 3.07       |\n",
      "|    reward             | 0.55405205 |\n",
      "|    std                | 3.7        |\n",
      "|    value_loss         | 0.282      |\n",
      "--------------------------------------\n"
     ]
    }
   ],
   "source": [
    "agent = DRLAgent(env=env_train) \n",
    "model_a2c = agent.get_model(\"a2c\")\n",
    "\n",
    "trained_a2c = agent.train_model(model=model_a2c, tb_log_name='a2c', total_timesteps=50000)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ArAnGULyVVfK",
   "metadata": {
    "id": "ArAnGULyVVfK"
   },
   "source": [
    "## Trade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "TzU6JBAWVGPG",
   "metadata": {
    "id": "TzU6JBAWVGPG"
   },
   "outputs": [],
   "source": [
    "\n",
    "trade = p.data_split(p.dataframe, TRADE_START_DATE, TRADE_END_DATE) \n",
    "env_kwargs = { \"stock_dim\": stock_dimension, \"hmax\": 1000, \"initial_amount\": 1000000, \"buy_cost_pct\": 6.87e-5, \"sell_cost_pct\": 1.0687e-3, \"reward_scaling\": 1e-4, \"state_space\": state_space, \"action_space\": stock_dimension, \"tech_indicator_list\": config.INDICATORS, \"print_verbosity\": 1, \"initial_buy\": False, \"hundred_each_trade\": True } \n",
    "e_trade_gym = StockTradingEnv(df=trade, **env_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fdg8qypiVSOn",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fdg8qypiVSOn",
    "outputId": "af6f6967-7e06-41c5-850f-d0e2512ecd43"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 2\n",
      "day: 103, episode: 2\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1023939.32\n",
      "total_reward: 23939.32\n",
      "total_cost: 68.68\n",
      "total_trades: 824\n",
      "Sharpe: 0.400\n",
      "=================================\n",
      "hit end!\n"
     ]
    }
   ],
   "source": [
    "df_account_value, df_actions = DRLAgent.DRL_prediction(model=trained_ddpg, environment=e_trade_gym)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "Ih4rdH3uVSo1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ih4rdH3uVSo1",
    "outputId": "291d8234-ee54-4ef2-a511-1e084a783f4e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>600000.SH</th>\n",
       "      <th>600009.SH</th>\n",
       "      <th>600016.SH</th>\n",
       "      <th>600028.SH</th>\n",
       "      <th>600030.SH</th>\n",
       "      <th>600031.SH</th>\n",
       "      <th>600036.SH</th>\n",
       "      <th>600050.SH</th>\n",
       "      <th>600104.SH</th>\n",
       "      <th>600196.SH</th>\n",
       "      <th>600276.SH</th>\n",
       "      <th>600309.SH</th>\n",
       "      <th>600519.SH</th>\n",
       "      <th>600547.SH</th>\n",
       "      <th>600570.SH</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-08-01</th>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-08-02</th>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-08-05</th>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-08-06</th>\n",
       "      <td>600</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-08-07</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-25</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-26</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-27</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-30</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-31</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>103 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            600000.SH  600009.SH  600016.SH  600028.SH  600030.SH  600031.SH  \\\n",
       "date                                                                           \n",
       "2019-08-01       1000       1000          0       1000          0       1000   \n",
       "2019-08-02       1000       1000          0       1000          0       1000   \n",
       "2019-08-05       1000       1000          0       1000          0       1000   \n",
       "2019-08-06        600          0          0       1000          0       1000   \n",
       "2019-08-07          0          0          0          0          0          0   \n",
       "...               ...        ...        ...        ...        ...        ...   \n",
       "2019-12-25          0          0          0          0          0          0   \n",
       "2019-12-26          0          0          0          0          0          0   \n",
       "2019-12-27          0          0          0          0          0          0   \n",
       "2019-12-30          0          0          0          0          0          0   \n",
       "2019-12-31          0          0          0          0          0          0   \n",
       "\n",
       "            600036.SH  600050.SH  600104.SH  600196.SH  600276.SH  600309.SH  \\\n",
       "date                                                                           \n",
       "2019-08-01          0          0       1000       1000          0          0   \n",
       "2019-08-02          0          0       1000       1000          0          0   \n",
       "2019-08-05          0          0       1000       1000          0          0   \n",
       "2019-08-06          0          0       1000       1000          0          0   \n",
       "2019-08-07          0          0          0          0          0          0   \n",
       "...               ...        ...        ...        ...        ...        ...   \n",
       "2019-12-25          0          0          0          0          0          0   \n",
       "2019-12-26          0          0          0          0          0          0   \n",
       "2019-12-27          0          0          0          0          0          0   \n",
       "2019-12-30          0          0          0          0          0          0   \n",
       "2019-12-31          0          0          0          0          0          0   \n",
       "\n",
       "            600519.SH  600547.SH  600570.SH  \n",
       "date                                         \n",
       "2019-08-01          0       1000       1000  \n",
       "2019-08-02          0       1000       1000  \n",
       "2019-08-05          0       1000       1000  \n",
       "2019-08-06          0       1000       1000  \n",
       "2019-08-07          0          0          0  \n",
       "...               ...        ...        ...  \n",
       "2019-12-25          0          0          0  \n",
       "2019-12-26          0          0          0  \n",
       "2019-12-27          0          0          0  \n",
       "2019-12-30          0          0          0  \n",
       "2019-12-31          0          0          0  \n",
       "\n",
       "[103 rows x 15 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_actions.to_csv(\"action.csv\", index=False) \n",
    "df_actions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "l7X1KIaVWUYp",
   "metadata": {
    "id": "l7X1KIaVWUYp"
   },
   "source": [
    "## Backtest"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dUJn8einWPKI",
   "metadata": {
    "id": "dUJn8einWPKI"
   },
   "source": [
    "### matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "pR6hNouKWOoY",
   "metadata": {
    "id": "pR6hNouKWOoY"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           time  account_value\n",
      "0    2019-08-01      1000000.0\n",
      "1    2019-08-02      1000000.0\n",
      "2    2019-08-05      1000000.0\n",
      "3    2019-08-06      1000000.0\n",
      "4    2019-08-07      1000000.0\n",
      "..          ...            ...\n",
      "99   2019-12-26      1000000.0\n",
      "100  2019-12-27      1000000.0\n",
      "101  2019-12-30      1000000.0\n",
      "102  2019-12-31      1000000.0\n",
      "103  2020-01-02      1000000.0\n",
      "\n",
      "[104 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "df_account_value.columns=[\"time\",\"account_value\"]\n",
    "print(df_account_value)\n",
    "\n",
    "plotter = ReturnPlotter(df_account_value, trade, TRADE_START_DATE, TRADE_END_DATE)\n",
    "plotter.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Qx62Q575YC9I",
   "metadata": {
    "id": "Qx62Q575YC9I"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "本接口即将停止更新，请尽快使用Pro版接口：https://tushare.pro/document/2\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# ticket: SSE 50：000016\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m plotter\u001b[39m.\u001b[39;49mplot(\u001b[39m\"\u001b[39;49m\u001b[39m000016\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[0;32m~/anaconda3/envs/FinEnv/lib/python3.10/site-packages/meta/data_processors/tushare.py:213\u001b[0m, in \u001b[0;36mReturnPlotter.plot\u001b[0;34m(self, baseline_ticket)\u001b[0m\n\u001b[1;32m    210\u001b[0m         baseline\u001b[39m.\u001b[39mappend(avg_close)\n\u001b[1;32m    211\u001b[0m     ours \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdf_account_value\u001b[39m.\u001b[39maccount_value\u001b[39m.\u001b[39mtolist()\n\u001b[0;32m--> 213\u001b[0m ours \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpct(ours)\n\u001b[1;32m    214\u001b[0m baseline \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpct(baseline)\n\u001b[1;32m    216\u001b[0m days_per_tick \u001b[39m=\u001b[39m (\n\u001b[1;32m    217\u001b[0m     \u001b[39m60\u001b[39m  \u001b[39m# you should scale this variable accroding to the total trading days\u001b[39;00m\n\u001b[1;32m    218\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/FinEnv/lib/python3.10/site-packages/meta/data_processors/tushare.py:309\u001b[0m, in \u001b[0;36mReturnPlotter.pct\u001b[0;34m(self, l)\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpct\u001b[39m(\u001b[39mself\u001b[39m, l):\n\u001b[1;32m    308\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Get percentage\"\"\"\u001b[39;00m\n\u001b[0;32m--> 309\u001b[0m     base \u001b[39m=\u001b[39m l[\u001b[39m0\u001b[39;49m]\n\u001b[1;32m    310\u001b[0m     \u001b[39mreturn\u001b[39;00m [x \u001b[39m/\u001b[39m base \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m l]\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# ticket: SSE 50：000016\n",
    "plotter.plot(\"000016\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "XUAh2S9Lamxe",
   "metadata": {
    "id": "XUAh2S9Lamxe"
   },
   "source": [
    "### CSI 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "NJZdXMGvYI9O",
   "metadata": {
    "id": "NJZdXMGvYI9O"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "本接口即将停止更新，请尽快使用Pro版接口：https://tushare.pro/document/2\n"
     ]
    }
   ],
   "source": [
    "baseline_df = plotter.get_baseline(\"399300\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ZSRJpKINYcBa",
   "metadata": {
    "id": "ZSRJpKINYcBa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============DRL Strategy Stats===========\n",
      "perf_stats_all: Annual return         -0.025429\n",
      "Cumulative returns    -0.010473\n",
      "Annual volatility      0.327358\n",
      "Sharpe ratio           0.085284\n",
      "Calmar ratio          -0.154956\n",
      "Stability              0.328101\n",
      "Max drawdown          -0.164107\n",
      "Omega ratio            1.016573\n",
      "Sortino ratio          0.114543\n",
      "Skew                        NaN\n",
      "Kurtosis                    NaN\n",
      "Tail ratio             1.040802\n",
      "Daily value at risk   -0.041132\n",
      "Alpha                       NaN\n",
      "Beta                        NaN\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "daily_return = plotter.get_return(df_account_value)\n",
    "daily_return_base = plotter.get_return(baseline_df, value_col_name=\"close\")\n",
    "\n",
    "perf_func = timeseries.perf_stats \n",
    "perf_stats_all = perf_func(returns=daily_return, factor_returns=daily_return_base, positions=None, transactions=None, turnover_denom=\"AGB\")\n",
    "print(\"==============DRL Strategy Stats===========\")\n",
    "print(f\"perf_stats_all: {perf_stats_all}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6J0LpdE7YuQe",
   "metadata": {
    "id": "6J0LpdE7YuQe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============Baseline Strategy Stats===========\n",
      "perf_stats_all: Annual return         NaN\n",
      "Cumulative returns    NaN\n",
      "Annual volatility     NaN\n",
      "Sharpe ratio          NaN\n",
      "Calmar ratio          NaN\n",
      "Stability             NaN\n",
      "Max drawdown          NaN\n",
      "Omega ratio           NaN\n",
      "Sortino ratio         NaN\n",
      "Skew                  NaN\n",
      "Kurtosis              NaN\n",
      "Tail ratio            NaN\n",
      "Daily value at risk   NaN\n",
      "Alpha                 NaN\n",
      "Beta                  NaN\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "daily_return = plotter.get_return(df_account_value)\n",
    "daily_return_base = plotter.get_return(baseline_df, value_col_name=\"close\")\n",
    "\n",
    "perf_func = timeseries.perf_stats\n",
    "perf_stats_all = perf_func(returns=daily_return_base, factor_returns=daily_return_base, positions=None, transactions=None, turnover_denom=\"AGB\")\n",
    "\n",
    "print(\"==============Baseline Strategy Stats===========\")\n",
    "\n",
    "print(f\"perf_stats_all: {perf_stats_all}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd64a2a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940a0174",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee140e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c44084",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32e112a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "China_A_share_market_tushare.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "finrl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "notify_time": "5",
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "afd6dc03c9be451573fc2885de79a969af6a24a159f11a3ead741ab7a9ff405f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
